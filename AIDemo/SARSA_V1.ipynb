{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading https://files.pythonhosted.org/packages/77/48/c43b8a72b916cc70896aa431b0fc00d1481ae34e28dc55e2144f4c77916b/gym-0.17.1.tar.gz (1.6MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\tan\\anaconda3\\lib\\site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\tan\\anaconda3\\lib\\site-packages (from gym) (1.16.4)\n",
      "Requirement already satisfied: six in c:\\users\\tan\\anaconda3\\lib\\site-packages (from gym) (1.12.0)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0 (from gym)\n",
      "  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in c:\\users\\tan\\anaconda3\\lib\\site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\tan\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.17.1)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\TAN\\AppData\\Local\\pip\\Cache\\wheels\\c0\\84\\61\\523b92d88787ae29689b3cc08cf445d8d8186d7fbe1acbf87b\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, gym\n",
      "Successfully installed gym-0.17.1 pyglet-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3,1,2,0)\n",
    "print(\"State:\", state)\n",
    "\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[328]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA ALGORITHM FOR TAXI PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Eps 0.899 Reward -207.2 State 476 Action 1\n",
      "Episode 300 Eps 0.5989999999999998 Reward -200.0 State 410 Action 0\n",
      "Episode 600 Eps 0.2989999999999995 Reward -176.403 State 410 Action 0\n",
      "Episode 900 Eps 0.009999999999999232 Reward -126.739 State 410 Action 0\n",
      "Episode 1200 Eps 0.009999999999999232 Reward -73.274 State 410 Action 0\n",
      "Episode 1500 Eps 0.009999999999999232 Reward -38.699 State 475 Action 0\n",
      "Episode 1800 Eps 0.009999999999999232 Reward -25.358 State 0 Action 0\n",
      "Episode 2100 Eps 0.009999999999999232 Reward -16.367 State 0 Action 0\n",
      "Episode 2400 Eps 0.009999999999999232 Reward -9.648 State 475 Action 0\n",
      "Episode 2700 Eps 0.009999999999999232 Reward -3.875 State 414 Action 3\n",
      "Episode 3000 Eps 0.009999999999999232 Reward -2.138 State 85 Action 0\n",
      "Episode 3300 Eps 0.009999999999999232 Reward 1.223 State 85 Action 0\n",
      "Episode 3600 Eps 0.009999999999999232 Reward 2.915 State 0 Action 0\n",
      "Episode 3900 Eps 0.009999999999999232 Reward 3.92 State 0 Action 0\n",
      "Episode 4200 Eps 0.009999999999999232 Reward 5.446 State 85 Action 0\n",
      "Episode 4500 Eps 0.009999999999999232 Reward 6.207 State 410 Action 0\n",
      "Episode 4800 Eps 0.009999999999999232 Reward 5.158 State 410 Action 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def eps_greedy(Q, s, eps=0.1):\n",
    "    '''\n",
    "    Epsilon greedy policy\n",
    "    '''\n",
    "    if np.random.uniform(0,1) < eps:\n",
    "        # Choose a random action\n",
    "        return np.random.randint(Q.shape[1])\n",
    "    else:\n",
    "        # Choose the action of a greedy policy\n",
    "        return greedy(Q, s)\n",
    "\n",
    "\n",
    "def greedy(Q, s):\n",
    "    '''\n",
    "    Greedy policy\n",
    "    return the index corresponding to the maximum action-state value\n",
    "    '''\n",
    "    return np.argmax(Q[s])\n",
    "\n",
    "\n",
    "def run_episodes(env, Q, num_episodes=100, to_print=False):\n",
    "    '''\n",
    "    Run some episodes to test the policy\n",
    "    '''\n",
    "    tot_rew = []\n",
    "    state = env.reset()\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        done = False\n",
    "        game_rew = 0\n",
    "\n",
    "        while not done:\n",
    "            # select a greedy action\n",
    "            next_state, rew, done, _ = env.step(greedy(Q, state))\n",
    "\n",
    "            state = next_state\n",
    "            game_rew += rew \n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                tot_rew.append(game_rew)\n",
    "\n",
    "    if to_print:\n",
    "        print('Mean score: %.3f of %i games!'%(np.mean(tot_rew), num_episodes))\n",
    "\n",
    "    return np.mean(tot_rew)\n",
    "\n",
    "\n",
    "def SARSA(env, lr=0.01, num_episodes=100, eps=0.3, gamma=0.95, eps_decay=0.00005):\n",
    "    nA = env.action_space.n\n",
    "    nS = env.observation_space.n\n",
    "\n",
    "    # Initialize the Q matrix\n",
    "    # Q: matrix nS*nA where each row represent a state and each colums represent a different action\n",
    "    Q = np.zeros((nS, nA))\n",
    "    games_reward = []\n",
    "    test_rewards = []\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        tot_rew = 0\n",
    "\n",
    "        # decay the epsilon value until it reaches the threshold of 0.01\n",
    "        if eps > 0.01:\n",
    "            eps -= eps_decay\n",
    "\n",
    "\n",
    "        action = eps_greedy(Q, state, eps) \n",
    "\n",
    "        # loop the main body until the environment stops\n",
    "        while not done:\n",
    "            next_state, rew, done, _ = env.step(action) # Take one step in the environment\n",
    "\n",
    "            # choose the next action (needed for the SARSA update)\n",
    "            next_action = eps_greedy(Q, next_state, eps) \n",
    "            # SARSA update\n",
    "            Q[state][action] = Q[state][action] + lr*(rew + gamma*Q[next_state][next_action] - Q[state][action])\n",
    "\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            tot_rew += rew\n",
    "            if done:\n",
    "                games_reward.append(tot_rew)\n",
    "\n",
    "        # Test the policy every 300 episodes and print the results\n",
    "        if (ep % 300) == 0:\n",
    "            test_rew = run_episodes(env, Q, 1000)\n",
    "            #print(\"Episode:{:5d}  Eps:{:2.4f}  Rew:{:2.4f}\".format(ep, eps, test_rew))\n",
    "            print(\"Episode\", ep, \"Eps\", eps, \"Reward\", test_rew, \"State\", state, \"Action\", action)\n",
    "            test_rewards.append(test_rew)\n",
    "\n",
    "    return Q,state,action\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('Taxi-v3')\n",
    "    #Q_sarsa = SARSA(env, lr=.1, num_episodes=3000, eps=0.4, gamma=0.95, eps_decay=0.001)\n",
    "    Q_sarsa = SARSA(env, lr=.1, num_episodes=5000, eps=0.9, gamma=0.9, eps_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
